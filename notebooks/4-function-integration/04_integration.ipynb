{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function Integration - Complete Pipeline\n",
        "\n",
        "This notebook integrates the functions from notebooks 2 and 3 into a complete document processing pipeline.\n",
        "\n",
        "## Functions Moved to src/ Modules\n",
        "\n",
        "All functions from notebooks 2 and 3 have been moved to the `src/` folder structure:\n",
        "- **OCR functions** → `src/ocr/`\n",
        "- **LLM functions** → `src/llm/`\n",
        "- **Storage functions** → `src/storage/`\n",
        "\n",
        "This allows for proper code organization and reusability across the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Start notebook 01 to run the docker containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Library Imports\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, List, Protocol\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to Python path so we can import from src/\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Force reload modules\n",
        "if 'src.ocr.postprocess' in sys.modules:\n",
        "    del sys.modules['src.ocr.postprocess']\n",
        "if 'src.ocr.easyocr_client' in sys.modules:\n",
        "    del sys.modules['src.ocr.easyocr_client']\n",
        "\n",
        "# Import functions from notebook 02 - OCR Text Extraction\n",
        "from src.ocr.easyocr_client import extract_text_bboxes_with_ocr\n",
        "from src.ocr.postprocess import normalize_ocr_lines, convert_numpy_types\n",
        "\n",
        "# Import functions from notebook 03 - LLM Field Extraction  \n",
        "from src.llm.field_extractor import extract_fields_with_llm\n",
        "from src.llm.client import OllamaClient, GenerativeLlm\n",
        "from src.llm.config import load_document_config\n",
        "\n",
        "# Import storage functions\n",
        "from src.storage.storage import get_storage, Stage\n",
        "from src.storage.blob_operations import write_ocr_results_to_bucket, read_ocr_results_from_bucket\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw?restype=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8c22df20-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 409\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'x-ms-error-code': 'ContainerAlreadyExists'\n",
            "    'x-ms-request-id': '37a930f3-a26d-490a-8930-c84472329219'\n",
            "    'content-type': 'application/xml'\n",
            "    'Date': 'Fri, 05 Sep 2025 00:23:29 GMT'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '147568'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8c252afa-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'etag': '\"0x1CDA682B0A3A460\"'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:23:29 GMT'\n",
            "    'content-md5': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8c252afa-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'x-ms-request-id': '782e3b02-b341-4795-9847-8bd5c758f98f'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:23:29 GMT'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Content-Length': '0'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BlobStorage initialized with multiple containers\n",
            "Container 'raw' already exists\n",
            "Uploaded blob: raw/test-document-001.pdf\n",
            "File successfully uploaded to blob storage at: raw/test-document-001.pdf\n"
          ]
        }
      ],
      "source": [
        "# Upload the loan application PDF to blob storage using the storage client\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "\n",
        "# Load file from data folder\n",
        "file_path = project_root / \"data\" / filename\n",
        "with open(file_path, \"rb\") as f:\n",
        "    file_data = f.read()\n",
        "\n",
        "# Upload to blob storage using the storage client\n",
        "storage_client = get_storage()\n",
        "storage_client.upload_blob(\n",
        "    uuid=document_id,\n",
        "    stage=Stage.RAW,\n",
        "    ext=\".pdf\",\n",
        "    data=file_data,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "blob_path = storage_client.blob_path(document_id, Stage.RAW, \".pdf\")\n",
        "print(f\"File successfully uploaded to blob storage at: {Stage.RAW.value}/{blob_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Loading\n",
        "\n",
        "Load system configuration from the config file to get LLM settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_system_config():\n",
        "    \"\"\"Load system configuration from config file.\"\"\"\n",
        "    with open(\"../../config/credit-ocr-system.conf\", 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    llm_match = re.search(r'generative_llm\\s*\\{\\s*url\\s*=\\s*\"([^\"]+)\"\\s*model_name\\s*=\\s*\"([^\"]+)\"\\s*\\}', content, re.DOTALL)\n",
        "    if llm_match:\n",
        "        return {\n",
        "            'llm': {\n",
        "                'url': llm_match.group(1),\n",
        "                'model_name': llm_match.group(2)\n",
        "            }\n",
        "        }\n",
        "    return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrated Pipeline\n",
        "\n",
        "This function combines all the processing steps into a single pipeline that processes a document from start to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "split of the pipeline into the components for OCR and LLM processing and visualization to keep it clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def process_document_with_ocr(document_id: str, pdf_data: bytes) -> Dict[str, Any]:\n",
        "    \"\"\"Process document with OCR and save results to blob storage.\"\"\"\n",
        "    print(f\"Processing document {document_id} with OCR...\")\n",
        "    \n",
        "    # Step 1: OCR Processing\n",
        "    print(\"  - Extracting text with OCR...\")\n",
        "    ocr_results, pdf_images = extract_text_bboxes_with_ocr(pdf_data)\n",
        "    print(f\"  - Extracted {len(ocr_results)} text elements\")\n",
        "    \n",
        "    # Step 2: Normalize OCR results\n",
        "    print(\"  - Normalizing OCR results...\")\n",
        "    normalized_results = normalize_ocr_lines(ocr_results)\n",
        "    print(f\"  - Normalized to {len(normalized_results)} structured items\")\n",
        "    \n",
        "    # Step 3: Convert NumPy types\n",
        "    print(\"  - Converting NumPy types...\")\n",
        "    ocr_results_converted = convert_numpy_types(ocr_results)\n",
        "    normalized_results_converted = convert_numpy_types(normalized_results)\n",
        "    \n",
        "    # Step 4: Prepare OCR results\n",
        "    ocr_processing_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"original_lines\": ocr_results_converted,\n",
        "        \"normalized_lines\": normalized_results_converted,\n",
        "        \"total_elements\": len(ocr_results_converted),\n",
        "        \"structured_items\": len(normalized_results_converted)\n",
        "    }\n",
        "    \n",
        "    # Step 5: Save OCR results to blob storage\n",
        "    print(\"  - Saving OCR results to blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    storage_client.upload_blob(\n",
        "        uuid=document_id,\n",
        "        stage=Stage.OCR,\n",
        "        ext=\".json\",\n",
        "        data=json.dumps(ocr_processing_results, indent=2, ensure_ascii=False).encode('utf-8'),\n",
        "        overwrite=True\n",
        "    )\n",
        "    \n",
        "    ocr_blob_path = storage_client.blob_path(document_id, Stage.OCR, \".json\")\n",
        "    print(f\"  - OCR results saved to: {Stage.OCR.value}/{ocr_blob_path}\")\n",
        "    \n",
        "    return ocr_processing_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def process_document_with_llm(document_id: str, ocr_results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Process document with LLM field extraction and save results to blob storage.\"\"\"\n",
        "    print(f\"Processing document {document_id} with LLM...\")\n",
        "    \n",
        "    # Step 1: Load configuration\n",
        "    print(\"  - Loading configuration...\")\n",
        "    system_config = load_system_config()\n",
        "    doc_config = load_document_config(\"../../config/document_types.conf\")\n",
        "    \n",
        "    # Step 2: Initialize LLM client\n",
        "    print(\"  - Initializing LLM client...\")\n",
        "    llm_client = OllamaClient(\n",
        "        base_url=system_config['llm']['url'],\n",
        "        model_name=system_config['llm']['model_name']\n",
        "    )\n",
        "    \n",
        "    # Step 3: Extract fields using LLM\n",
        "    print(\"  - Extracting fields with LLM...\")\n",
        "    extraction_result = await extract_fields_with_llm(\n",
        "        ocr_lines=ocr_results[\"normalized_lines\"],\n",
        "        doc_config=doc_config[\"credit_request\"],\n",
        "        llm_client=llm_client,\n",
        "        original_ocr_lines=ocr_results[\"original_lines\"]\n",
        "    )\n",
        "    \n",
        "    # Step 4: Prepare LLM results\n",
        "    llm_processing_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"extracted_fields\": extraction_result.get(\"extracted_fields\", {}),\n",
        "        \"missing_fields\": extraction_result.get(\"missing_fields\", []),\n",
        "        \"validation_results\": extraction_result.get(\"validation_results\", {}),\n",
        "        \"llm_metadata\": {\n",
        "            \"model_used\": system_config['llm']['model_name'],\n",
        "            \"extraction_method\": \"llm_assisted\"\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Step 5: Save LLM results to blob storage\n",
        "    print(\"  - Saving LLM results to blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    storage_client.upload_blob(\n",
        "        uuid=document_id,\n",
        "        stage=Stage.LLM,\n",
        "        ext=\".json\",\n",
        "        data=json.dumps(llm_processing_results, indent=2, ensure_ascii=False).encode('utf-8'),\n",
        "        overwrite=True\n",
        "    )\n",
        "    \n",
        "    llm_blob_path = storage_client.blob_path(document_id, Stage.LLM, \".json\")\n",
        "    print(f\"  - LLM results saved to: {Stage.LLM.value}/{llm_blob_path}\")\n",
        "    \n",
        "    return llm_processing_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def integrated_pipeline(document_id: str, filename: str, blob_path: str):\n",
        "    \"\"\"Complete integrated pipeline combining document loading from blob storage, OCR and LLM processing.\"\"\"\n",
        "    \n",
        "    print(f\"Starting integrated pipeline for document: {document_id}\")\n",
        "    print(f\"  - Filename: {filename}\")\n",
        "    print(f\"  - Blob path: {blob_path}\")\n",
        "    \n",
        "    # Step 1: Load document from blob storage\n",
        "    print(\"Step 1: Loading document from blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    pdf_data = storage_client.download_blob(document_id, Stage.RAW, \".pdf\")\n",
        "    if pdf_data is None:\n",
        "        raise FileNotFoundError(f\"Document not found in blob storage: {document_id}\")\n",
        "    print(f\"  - Loaded {filename} from blob storage ({len(pdf_data)} bytes)\")\n",
        "    \n",
        "    # Step 2: OCR Processing using modular function\n",
        "    print(\"Step 2: OCR Processing...\")\n",
        "    ocr_results = await process_document_with_ocr(document_id, pdf_data)\n",
        "    \n",
        "    # Step 3: LLM Processing using modular function\n",
        "    print(\"Step 3: LLM Field Extraction...\")\n",
        "    llm_results = await process_document_with_llm(document_id, ocr_results)\n",
        "    \n",
        "    # Step 4: Prepare final results\n",
        "    final_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"document_info\": {\n",
        "            \"filename\": filename,\n",
        "            \"file_size\": len(pdf_data),\n",
        "            \"source\": \"blob_storage\",\n",
        "            \"blob_path\": blob_path\n",
        "        },\n",
        "        \"ocr_results\": ocr_results,\n",
        "        \"llm_results\": llm_results,\n",
        "        \"status\": \"completed\"\n",
        "    }\n",
        "    \n",
        "    print(\"Step 4: Pipeline completed successfully!\")\n",
        "    print(f\"  - Extracted {len(llm_results.get('extracted_fields', {}))} fields\")\n",
        "    print(f\"  - Missing {len(llm_results.get('missing_fields', []))} fields\")\n",
        "\n",
        "    # TODO: Add visualization of OCR results and save to blob storage\n",
        "    \n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "Execute the complete integrated pipeline to process the loan application document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the document that was uploaded to blob storage\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "blob_path = f\"{Stage.RAW.value}/{document_id}.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modular Processing Functions\n",
        "\n",
        "Separate functions for OCR and LLM processing that can be reused and tested independently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'GET'\n",
            "Request headers:\n",
            "    'x-ms-range': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8c29dffa-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 206\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:23:29 GMT'\n",
            "    'x-ms-creation-time': 'REDACTED'\n",
            "    'content-length': '147568'\n",
            "    'content-type': 'application/octet-stream'\n",
            "    'content-range': 'REDACTED'\n",
            "    'etag': '\"0x1CDA682B0A3A460\"'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-lease-state': 'REDACTED'\n",
            "    'x-ms-lease-status': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8c29dffa-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'x-ms-request-id': '75e4a153-9dd9-4d38-9047-71ff54b8cd83'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'accept-ranges': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:23:29 GMT'\n",
            "    'x-ms-server-encrypted': 'REDACTED'\n",
            "    'x-ms-blob-content-md5': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting integrated pipeline for document: test-document-001\n",
            "  - Filename: loan_application.pdf\n",
            "  - Blob path: raw/test-document-001.pdf\n",
            "Step 1: Loading document from blob storage...\n",
            "Downloaded blob: raw/test-document-001.pdf\n",
            "  - Loaded loan_application.pdf from blob storage (147568 bytes)\n",
            "Step 2: OCR Processing...\n",
            "Processing document test-document-001 with OCR...\n",
            "  - Extracting text with OCR...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.ocr.easyocr_client:Processing PDF from bytes (size: 147568 bytes)\n",
            "INFO:src.ocr.easyocr_client:Successfully converted PDF to 1 images\n",
            "/Users/markuskuehnle/Documents/projects/credit-ocr-system/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/ocr?restype=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8e261062-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 409\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'x-ms-error-code': 'ContainerAlreadyExists'\n",
            "    'x-ms-request-id': '46421dd3-87c4-4760-a9e5-28ec6a517dae'\n",
            "    'content-type': 'application/xml'\n",
            "    'Date': 'Fri, 05 Sep 2025 00:23:32 GMT'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/ocr/test-document-001.json'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '24171'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8e278db6-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'etag': '\"0x2163A9609676880\"'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:23:32 GMT'\n",
            "    'content-md5': 'REDACTED'\n",
            "    'x-ms-client-request-id': '8e278db6-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'x-ms-request-id': '09feb4b4-bac8-4691-9d82-6da0e8a2a327'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:23:32 GMT'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Content-Length': '0'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Extracted 62 text elements\n",
            "  - Normalizing OCR results...\n",
            "  - Normalized to 26 structured items\n",
            "  - Converting NumPy types...\n",
            "  - Saving OCR results to blob storage...\n",
            "Container 'ocr' already exists\n",
            "Uploaded blob: ocr/test-document-001.json\n",
            "  - OCR results saved to: ocr/test-document-001.json\n",
            "Step 3: LLM Field Extraction...\n",
            "Processing document test-document-001 with LLM...\n",
            "  - Loading configuration...\n",
            "  - Initializing LLM client...\n",
            "  - Extracting fields with LLM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/llm?restype=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'bcac421c-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 409\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'x-ms-error-code': 'ContainerAlreadyExists'\n",
            "    'x-ms-request-id': 'd4a0655d-a1a2-4f1f-9c46-0eeb8c068f9a'\n",
            "    'content-type': 'application/xml'\n",
            "    'Date': 'Fri, 05 Sep 2025 00:24:50 GMT'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/llm/test-document-001.json'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '6538'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'bcacfdba-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'Authorization': 'REDACTED'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'etag': '\"0x1EC24CCF9081CD0\"'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:24:50 GMT'\n",
            "    'content-md5': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'bcacfdba-89ee-11f0-ab5c-8f2c2434f4a8'\n",
            "    'x-ms-request-id': '5aa30fe4-0da3-4138-ac41-97da98e98d25'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:24:50 GMT'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Content-Length': '0'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Saving LLM results to blob storage...\n",
            "Container 'llm' already exists\n",
            "Uploaded blob: llm/test-document-001.json\n",
            "  - LLM results saved to: llm/test-document-001.json\n",
            "Step 4: Pipeline completed successfully!\n",
            "  - Extracted 21 fields\n",
            "  - Missing 0 fields\n",
            "==================================================\n",
            "PIPELINE COMPLETED SUCCESSFULLY!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "results = await integrated_pipeline(document_id, filename, blob_path)\n",
        "print(\"=\" * 50)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 50)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
