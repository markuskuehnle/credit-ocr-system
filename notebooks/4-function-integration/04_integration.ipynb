{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function Integration - Complete Pipeline\n",
        "\n",
        "This notebook integrates the functions from notebooks 2 and 3 into a complete document processing pipeline.\n",
        "\n",
        "## Functions Moved to src/ Modules\n",
        "\n",
        "All functions from notebooks 2 and 3 have been moved to the `src/` folder structure:\n",
        "- **OCR functions** → `src/ocr/`\n",
        "- **LLM functions** → `src/llm/`\n",
        "- **Storage functions** → `src/storage/`\n",
        "\n",
        "This allows for proper code organization and reusability across the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Start notebook 01 to run the docker containers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Library Imports\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, List, Protocol\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add project root to Python path so we can import from src/\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force reload modules\n",
        "if 'src.ocr.postprocess' in sys.modules:\n",
        "    del sys.modules['src.ocr.postprocess']\n",
        "if 'src.ocr.easyocr_client' in sys.modules:\n",
        "    del sys.modules['src.ocr.easyocr_client']\n",
        "\n",
        "# Import functions from notebook 02 - OCR Text Extraction\n",
        "from src.ocr.easyocr_client import extract_text_bboxes_with_ocr\n",
        "from src.ocr.postprocess import normalize_ocr_lines, convert_numpy_types\n",
        "\n",
        "# Import functions from notebook 03 - LLM Field Extraction  \n",
        "from src.llm.field_extractor import extract_fields_with_llm\n",
        "from src.llm.client import OllamaClient, GenerativeLlm\n",
        "from src.llm.config import load_document_config\n",
        "\n",
        "# Import storage functions\n",
        "from src.storage.storage import get_storage, Stage\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '147568'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b3a81bee-89ff-11f0-84dc-e74738fd7768'\n",
            "    'Authorization': 'REDACTED'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'etag': '\"0x1C7A74F9AA53950\"'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 02:26:17 GMT'\n",
            "    'content-md5': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b3a81bee-89ff-11f0-84dc-e74738fd7768'\n",
            "    'x-ms-request-id': '468bcbc6-8eca-4df5-9f5e-c497f89efadd'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 02:26:17 GMT'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Content-Length': '0'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded blob: raw/test-document-001.pdf\n",
            "File successfully uploaded to blob storage at: raw/test-document-001.pdf\n"
          ]
        }
      ],
      "source": [
        "# Upload the loan application PDF to blob storage using the storage client\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "\n",
        "# Load file from data folder\n",
        "file_path = project_root / \"data\" / filename\n",
        "with open(file_path, \"rb\") as f:\n",
        "    file_data = f.read()\n",
        "\n",
        "# Upload to blob storage using the storage client\n",
        "storage_client = get_storage()\n",
        "storage_client.upload_blob(\n",
        "    uuid=document_id,\n",
        "    stage=Stage.RAW,\n",
        "    ext=\".pdf\",\n",
        "    data=file_data,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "blob_path = storage_client.blob_path(document_id, Stage.RAW, \".pdf\")\n",
        "print(f\"File successfully uploaded to blob storage at: {Stage.RAW.value}/{blob_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Loading\n",
        "\n",
        "Load system configuration from the config file to get LLM settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_system_config():\n",
        "    \"\"\"Load system configuration from config file.\"\"\"\n",
        "    with open(\"../../config/credit-ocr-system.conf\", 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    llm_match = re.search(r'generative_llm\\s*\\{\\s*url\\s*=\\s*\"([^\"]+)\"\\s*model_name\\s*=\\s*\"([^\"]+)\"\\s*\\}', content, re.DOTALL)\n",
        "    if llm_match:\n",
        "        return {\n",
        "            'llm': {\n",
        "                'url': llm_match.group(1),\n",
        "                'model_name': llm_match.group(2)\n",
        "            }\n",
        "        }\n",
        "    return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrated Pipeline\n",
        "\n",
        "This function combines all the processing steps into a single pipeline that processes a document from start to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "split of the pipeline into the components for OCR and LLM processing and visualization to keep it clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def process_document_with_ocr(document_id: str, pdf_data: bytes) -> Dict[str, Any]:\n",
        "    \"\"\"Process document with OCR and save results to blob storage.\"\"\"\n",
        "    print(f\"Processing document {document_id} with OCR...\")\n",
        "    \n",
        "    # Step 1: OCR Processing\n",
        "    print(\"  - Extracting text with OCR...\")\n",
        "    ocr_results, pdf_images = extract_text_bboxes_with_ocr(pdf_data)\n",
        "    print(f\"  - Extracted {len(ocr_results)} text elements\")\n",
        "    \n",
        "    # Step 2: Normalize OCR results\n",
        "    print(\"  - Normalizing OCR results...\")\n",
        "    normalized_results = normalize_ocr_lines(ocr_results)\n",
        "    print(f\"  - Normalized to {len(normalized_results)} structured items\")\n",
        "    \n",
        "    # Step 3: Convert NumPy types\n",
        "    print(\"  - Converting NumPy types...\")\n",
        "    ocr_results_converted = convert_numpy_types(ocr_results)\n",
        "    normalized_results_converted = convert_numpy_types(normalized_results)\n",
        "    \n",
        "    # Step 4: Prepare OCR results\n",
        "    ocr_processing_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"original_lines\": ocr_results_converted,\n",
        "        \"normalized_lines\": normalized_results_converted,\n",
        "        \"total_elements\": len(ocr_results_converted),\n",
        "        \"structured_items\": len(normalized_results_converted)\n",
        "    }\n",
        "    \n",
        "    # Step 5: Save OCR results to blob storage\n",
        "    print(\"  - Saving OCR results to blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    storage_client.upload_document_data(\n",
        "        uuid=document_id,\n",
        "        stage=Stage.OCR,\n",
        "        ext=\".json\",\n",
        "        data=ocr_processing_results,\n",
        "        metadata={}\n",
        "    )\n",
        "    \n",
        "    ocr_blob_path = storage_client.blob_path(document_id, Stage.OCR, \".json\")\n",
        "    print(f\"  - OCR results saved to: {Stage.OCR.value}/{ocr_blob_path}\")\n",
        "    \n",
        "    return ocr_processing_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def process_document_with_llm(document_id: str, ocr_results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Process document with LLM field extraction and save results to blob storage.\"\"\"\n",
        "    print(f\"Processing document {document_id} with LLM...\")\n",
        "    \n",
        "    # Step 1: Load configuration\n",
        "    print(\"  - Loading configuration...\")\n",
        "    system_config = load_system_config()\n",
        "    doc_config = load_document_config(\"../../config/document_types.conf\")\n",
        "    \n",
        "    # Step 2: Initialize LLM client\n",
        "    print(\"  - Initializing LLM client...\")\n",
        "    llm_client = OllamaClient(\n",
        "        base_url=system_config['llm']['url'],\n",
        "        model_name=system_config['llm']['model_name']\n",
        "    )\n",
        "    \n",
        "    # Step 3: Extract fields using LLM\n",
        "    print(\"  - Extracting fields with LLM...\")\n",
        "    extraction_result = await extract_fields_with_llm(\n",
        "        ocr_lines=ocr_results[\"normalized_lines\"],\n",
        "        doc_config=doc_config[\"credit_request\"],\n",
        "        llm_client=llm_client,\n",
        "        original_ocr_lines=ocr_results[\"original_lines\"]\n",
        "    )\n",
        "    \n",
        "    # Step 4: Prepare LLM results\n",
        "    llm_processing_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"extracted_fields\": extraction_result.get(\"extracted_fields\", {}),\n",
        "        \"missing_fields\": extraction_result.get(\"missing_fields\", []),\n",
        "        \"validation_results\": extraction_result.get(\"validation_results\", {}),\n",
        "        \"llm_metadata\": {\n",
        "            \"model_used\": system_config['llm']['model_name'],\n",
        "            \"extraction_method\": \"llm_assisted\"\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Step 5: Save LLM results to blob storage\n",
        "    print(\"  - Saving LLM results to blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    storage_client.upload_document_data(\n",
        "        uuid=document_id,\n",
        "        stage=Stage.LLM,\n",
        "        ext=\".json\",\n",
        "        data=llm_processing_results,\n",
        "        metadata={\n",
        "            \"processing_method\": system_config['llm']['model_name']\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    llm_blob_path = storage_client.blob_path(document_id, Stage.LLM, \".json\")\n",
        "    print(f\"  - LLM results saved to: {Stage.LLM.value}/{llm_blob_path}\")\n",
        "    \n",
        "    return llm_processing_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization function from notebook 02\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_ocr_results(document_id: str, ocr_results: List[Dict[str, Any]]) -> None:\n",
        "    \"\"\"Visualize OCR bounding boxes, text, and confidence on images and save to blob storage.\"\"\"\n",
        "    from io import BytesIO\n",
        "    from pdf2image import convert_from_bytes\n",
        "    \n",
        "    # Download PDF from blob storage\n",
        "    storage_client = get_storage()\n",
        "    pdf_data = storage_client.download_blob(document_id, Stage.RAW, \".pdf\")\n",
        "    if pdf_data is None:\n",
        "        raise FileNotFoundError(f\"PDF not found in blob storage: {document_id}\")\n",
        "    \n",
        "    # Convert PDF to images with SAME DPI as OCR processing (150)\n",
        "    print(\"  - Converting PDF to images for visualization...\")\n",
        "    pdf_images = convert_from_bytes(pdf_data, dpi=150)  # Changed from 200 to 150\n",
        "    print(f\"  - Converted PDF to {len(pdf_images)} images\")\n",
        "    \n",
        "    # Group OCR results by page\n",
        "    page_to_elements: Dict[int, List[Dict[str, Any]]] = {}\n",
        "    for result in ocr_results:\n",
        "        page_num: int = result[\"page_num\"]\n",
        "        if page_num not in page_to_elements:\n",
        "            page_to_elements[page_num] = []\n",
        "        page_to_elements[page_num].append(result)\n",
        "    \n",
        "    # Create visualizations for each page\n",
        "    for page_num, elements in page_to_elements.items():\n",
        "        image = pdf_images[page_num - 1]\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(15, 20))\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f'Page {page_num} - OCR Text Extraction', fontsize=16)\n",
        "        \n",
        "        for element in elements:\n",
        "            bbox = element['bbox']\n",
        "            text = element['text']\n",
        "            confidence = element['confidence']\n",
        "            color = 'green' if confidence >= 0.9 else 'orange' if confidence >= 0.7 else 'red'\n",
        "            \n",
        "            rect = patches.Rectangle(\n",
        "                (bbox['x1'], bbox['y1']),\n",
        "                bbox['width'],\n",
        "                bbox['height'],\n",
        "                linewidth=1.5,\n",
        "                edgecolor=color,\n",
        "                facecolor='none',\n",
        "                alpha=0.8\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            \n",
        "            display_text = text[:30] + ('...' if len(text) > 30 else '')\n",
        "            label = f\"{display_text} ({confidence*100:.1f}%)\"\n",
        "            ax.annotate(\n",
        "                label,\n",
        "                (bbox['x1'], bbox['y1'] - 5),\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=color, alpha=0.9),\n",
        "                fontsize=7,\n",
        "                color='black',\n",
        "                ha='left',\n",
        "                va='bottom'\n",
        "            )\n",
        "        \n",
        "        legend_elements = [\n",
        "            patches.Patch(color='green', label='High (≥90%)'),\n",
        "            patches.Patch(color='orange', label='Med (70-89%)'),\n",
        "            patches.Patch(color='red', label='Low (<70%)')\n",
        "        ]\n",
        "        ax.legend(handles=legend_elements, loc='upper right')\n",
        "        ax.set_xlim(0, image.width)\n",
        "        ax.set_ylim(image.height, 0)\n",
        "        ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save visualization to blob storage\n",
        "        buffer = BytesIO()\n",
        "        plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')\n",
        "        buffer.seek(0)\n",
        "        \n",
        "        # Upload to blob storage with ANNOTATED stage\n",
        "        storage_client.upload_blob(\n",
        "            uuid=document_id,\n",
        "            stage=Stage.ANNOTATED,\n",
        "            ext=f\"_page_{page_num}.png\",\n",
        "            data=buffer.getvalue(),\n",
        "            overwrite=True\n",
        "        )\n",
        "        \n",
        "        annotated_blob_path = storage_client.blob_path(document_id, Stage.ANNOTATED, f\"_page_{page_num}.png\")\n",
        "        print(f\"  - Visualization saved to: {Stage.ANNOTATED.value}/{annotated_blob_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()  # Close the figure to free memory\n",
        "        \n",
        "        high = sum(1 for e in elements if e['confidence'] >= 0.9)\n",
        "        med = sum(1 for e in elements if 0.7 <= e['confidence'] < 0.9)\n",
        "        low = sum(1 for e in elements if e['confidence'] < 0.7)\n",
        "        avg = sum(e['confidence'] for e in elements) / len(elements) if elements else 0\n",
        "        print(f\"Page {page_num}: {len(elements)} elements | Avg: {avg*100:.1f}% | H:{high} M:{med} L:{low}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def integrated_pipeline(document_id: str, filename: str, blob_path: str):\n",
        "    \"\"\"Complete integrated pipeline combining document loading from blob storage, OCR and LLM processing.\"\"\"\n",
        "    \n",
        "    print(f\"Starting integrated pipeline for document: {document_id}\")\n",
        "    print(f\"  - Filename: {filename}\")\n",
        "    print(f\"  - Blob path: {blob_path}\")\n",
        "    \n",
        "    # Step 1: Load document from blob storage\n",
        "    print(\"Step 1: Loading document from blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    pdf_data = storage_client.download_blob(document_id, Stage.RAW, \".pdf\")\n",
        "    if pdf_data is None:\n",
        "        raise FileNotFoundError(f\"Document not found in blob storage: {document_id}\")\n",
        "    print(f\"  - Loaded {filename} from blob storage ({len(pdf_data)} bytes)\")\n",
        "    \n",
        "    # Step 2: OCR Processing using modular function\n",
        "    print(\"Step 2: OCR Processing...\")\n",
        "    ocr_results = await process_document_with_ocr(document_id, pdf_data)\n",
        "    \n",
        "    # Step 3: LLM Processing using modular function\n",
        "    print(\"Step 3: LLM Field Extraction...\")\n",
        "    llm_results = await process_document_with_llm(document_id, ocr_results)\n",
        "    \n",
        "    # Step 4: Visualize OCR results\n",
        "    print(\"Step 4: Visualizing OCR results...\")\n",
        "    visualize_ocr_results(document_id, ocr_results[\"original_lines\"])\n",
        "    \n",
        "    # Step 5: Prepare final results\n",
        "    final_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"document_info\": {\n",
        "            \"filename\": filename,\n",
        "            \"file_size\": len(pdf_data),\n",
        "            \"source\": \"blob_storage\",\n",
        "            \"blob_path\": blob_path\n",
        "        },\n",
        "        \"ocr_results\": ocr_results,\n",
        "        \"llm_results\": llm_results,\n",
        "        \"status\": \"completed\"\n",
        "    }\n",
        "    \n",
        "    print(\"Step 5: Pipeline completed successfully!\")\n",
        "    print(f\"  - Extracted {len(llm_results.get('extracted_fields', {}))} fields\")\n",
        "    print(f\"  - Missing {len(llm_results.get('missing_fields', []))} fields\")\n",
        "    \n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "Execute the complete integrated pipeline to process the loan application document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the document that was uploaded to blob storage\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "blob_path = f\"{Stage.RAW.value}/{document_id}.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modular Processing Functions\n",
        "\n",
        "Separate functions for OCR and LLM processing that can be reused and tested independently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'GET'\n",
            "Request headers:\n",
            "    'x-ms-range': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b3af6264-89ff-11f0-84dc-e74738fd7768'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 206\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 02:26:17 GMT'\n",
            "    'x-ms-creation-time': 'REDACTED'\n",
            "    'content-length': '147568'\n",
            "    'content-type': 'application/octet-stream'\n",
            "    'content-range': 'REDACTED'\n",
            "    'etag': '\"0x1C7A74F9AA53950\"'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-lease-state': 'REDACTED'\n",
            "    'x-ms-lease-status': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b3af6264-89ff-11f0-84dc-e74738fd7768'\n",
            "    'x-ms-request-id': '0ad22797-8c3d-44b6-9c1b-e81c355df067'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'accept-ranges': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 02:26:17 GMT'\n",
            "    'x-ms-server-encrypted': 'REDACTED'\n",
            "    'x-ms-blob-content-md5': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n"
          ]
        }
      ],
      "source": [
        "results = await integrated_pipeline(document_id, filename, blob_path)\n",
        "print(\"=\" * 50)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'now, we see that this works so we move these functions also to the /src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
