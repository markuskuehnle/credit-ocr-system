{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function Integration - Complete Pipeline\n",
        "\n",
        "This notebook integrates the functions from notebooks 2 and 3 into a complete document processing pipeline.\n",
        "\n",
        "## Functions Moved to src/ Modules\n",
        "\n",
        "All functions from notebooks 2 and 3 have been moved to the `src/` folder structure:\n",
        "- **OCR functions** → `src/ocr/`\n",
        "- **LLM functions** → `src/llm/`\n",
        "- **Storage functions** → `src/storage/`\n",
        "\n",
        "This allows for proper code organization and reusability across the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Library Imports\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, List, Protocol\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to Python path so we can import from src/\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Force reload modules\n",
        "if 'src.ocr.postprocess' in sys.modules:\n",
        "    del sys.modules['src.ocr.postprocess']\n",
        "if 'src.ocr.easyocr_client' in sys.modules:\n",
        "    del sys.modules['src.ocr.easyocr_client']\n",
        "\n",
        "# Import functions from notebook 02 - OCR Text Extraction\n",
        "from src.ocr.easyocr_client import extract_text_bboxes_with_ocr\n",
        "from src.ocr.postprocess import normalize_ocr_lines, convert_numpy_types\n",
        "\n",
        "# Import functions from notebook 03 - LLM Field Extraction  \n",
        "from src.llm.field_extractor import extract_fields_with_llm\n",
        "from src.llm.client import OllamaClient, GenerativeLlm\n",
        "from src.llm.config import load_document_config\n",
        "\n",
        "# Import storage functions\n",
        "from src.storage.storage import get_storage, Stage\n",
        "from src.storage.blob_operations import write_ocr_results_to_bucket, read_ocr_results_from_bucket\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw?restype=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'c396729e-89eb-11f0-9d9c-a526edf9c303'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 409\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'x-ms-error-code': 'ContainerAlreadyExists'\n",
            "    'x-ms-request-id': '90b0cff2-d89b-4b7d-9bab-5b990b2726f7'\n",
            "    'content-type': 'application/xml'\n",
            "    'Date': 'Fri, 05 Sep 2025 00:03:34 GMT'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '147568'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'c398aa6e-89eb-11f0-9d9c-a526edf9c303'\n",
            "    'Authorization': 'REDACTED'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'etag': '\"0x23DB91A2D5C27A0\"'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:03:34 GMT'\n",
            "    'content-md5': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'c398aa6e-89eb-11f0-9d9c-a526edf9c303'\n",
            "    'x-ms-request-id': '8b7820ab-4aea-4cb4-ac06-465b7103304e'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:03:34 GMT'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n",
            "    'Content-Length': '0'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BlobStorage initialized with multiple containers\n",
            "Container 'raw' already exists\n",
            "Uploaded blob: raw/test-document-001.pdf\n",
            "File successfully uploaded to blob storage at: raw/test-document-001.pdf\n"
          ]
        }
      ],
      "source": [
        "# Upload the loan application PDF to blob storage using the storage client\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "\n",
        "# Load file from data folder\n",
        "file_path = project_root / \"data\" / filename\n",
        "with open(file_path, \"rb\") as f:\n",
        "    file_data = f.read()\n",
        "\n",
        "# Upload to blob storage using the storage client\n",
        "storage_client = get_storage()\n",
        "storage_client.upload_blob(\n",
        "    uuid=document_id,\n",
        "    stage=Stage.RAW,\n",
        "    ext=\".pdf\",\n",
        "    data=file_data,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "blob_path = storage_client.blob_path(document_id, Stage.RAW, \".pdf\")\n",
        "print(f\"File successfully uploaded to blob storage at: {Stage.RAW.value}/{blob_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Loading\n",
        "\n",
        "Load system configuration from the config file to get LLM settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_system_config():\n",
        "    \"\"\"Load system configuration from config file.\"\"\"\n",
        "    with open(\"../../config/credit-ocr-system.conf\", 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    llm_match = re.search(r'generative_llm\\s*\\{\\s*url\\s*=\\s*\"([^\"]+)\"\\s*model_name\\s*=\\s*\"([^\"]+)\"\\s*\\}', content, re.DOTALL)\n",
        "    if llm_match:\n",
        "        return {\n",
        "            'llm': {\n",
        "                'url': llm_match.group(1),\n",
        "                'model_name': llm_match.group(2)\n",
        "            }\n",
        "        }\n",
        "    return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrated Pipeline\n",
        "\n",
        "This function combines all the processing steps into a single pipeline that processes a document from start to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def integrated_pipeline(document_id: str, filename: str, blob_path: str):\n",
        "    \"\"\"Complete integrated pipeline combining document loading from blob storage, OCR and LLM processing.\"\"\"\n",
        "    \n",
        "    print(f\"Starting integrated pipeline for document: {document_id}\")\n",
        "    print(f\"  - Filename: {filename}\")\n",
        "    print(f\"  - Blob path: {blob_path}\")\n",
        "    \n",
        "    # Step 1: Load document from blob storage\n",
        "    print(\"Step 1: Loading document from blob storage...\")\n",
        "    storage_client = get_storage()\n",
        "    pdf_data = storage_client.download_blob(document_id, Stage.RAW, \".pdf\")\n",
        "    if pdf_data is None:\n",
        "        raise FileNotFoundError(f\"Document not found in blob storage: {document_id}\")\n",
        "    print(f\"  - Loaded {filename} from blob storage ({len(pdf_data)} bytes)\")\n",
        "    \n",
        "    # Step 2: OCR Processing (from notebook 2)\n",
        "    print(\"Step 2: OCR Processing...\")\n",
        "    ocr_results, pdf_images = extract_text_bboxes_with_ocr(pdf_data)\n",
        "    print(f\"  - Extracted {len(ocr_results)} text elements\")\n",
        "    \n",
        "    # Step 3: Normalize OCR results\n",
        "    print(\"Step 3: Normalizing OCR results...\")\n",
        "    normalized_results = normalize_ocr_lines(ocr_results)\n",
        "    print(f\"  - Normalized to {len(normalized_results)} structured items\")\n",
        "    \n",
        "    # Step 4: Convert NumPy types\n",
        "    print(\"Step 4: Converting NumPy types...\")\n",
        "    ocr_results_converted = convert_numpy_types(ocr_results)\n",
        "    normalized_results_converted = convert_numpy_types(normalized_results)\n",
        "    \n",
        "    # Step 5: LLM Processing (from notebook 3)\n",
        "    print(\"Step 5: LLM Field Extraction...\")\n",
        "    \n",
        "    # Load configuration\n",
        "    system_config = load_system_config()\n",
        "    doc_config = load_document_config(\"../../config/document_types.conf\")\n",
        "    \n",
        "    # Initialize LLM client\n",
        "    llm_client = OllamaClient(\n",
        "        base_url=system_config['llm']['url'],\n",
        "        model_name=system_config['llm']['model_name']\n",
        "    )\n",
        "    \n",
        "    # Extract fields using LLM\n",
        "    extraction_result = await extract_fields_with_llm(\n",
        "        ocr_lines=normalized_results_converted,\n",
        "        doc_config=doc_config[\"credit_request\"],\n",
        "        llm_client=llm_client,\n",
        "        original_ocr_lines=ocr_results_converted\n",
        "    )\n",
        "    \n",
        "    # Step 6: Prepare final results\n",
        "    final_results = {\n",
        "        \"document_id\": document_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"document_info\": {\n",
        "            \"filename\": filename,\n",
        "            \"file_size\": len(pdf_data),\n",
        "            \"blob_path\": blob_path\n",
        "        },\n",
        "        \"ocr_results\": {\n",
        "            \"original_lines\": ocr_results_converted,\n",
        "            \"normalized_lines\": normalized_results_converted,\n",
        "            \"total_elements\": len(ocr_results_converted),\n",
        "            \"structured_items\": len(normalized_results_converted)\n",
        "        },\n",
        "        \"llm_results\": extraction_result,\n",
        "        \"status\": \"completed\"\n",
        "    }\n",
        "    \n",
        "    print(\"Step 6: Pipeline completed successfully!\")\n",
        "    print(f\"  - Extracted {len(extraction_result.get('extracted_fields', {}))} fields\")\n",
        "    print(f\"  - Missing {len(extraction_result.get('missing_fields', []))} fields\")\n",
        "    \n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "Execute the complete integrated pipeline to process the loan application document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://127.0.0.1:10000/devstoreaccount1/raw/test-document-001.pdf'\n",
            "Request method: 'GET'\n",
            "Request headers:\n",
            "    'x-ms-range': 'REDACTED'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.26.0 Python/3.10.16 (macOS-15.1-arm64-arm-64bit)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'c39cad62-89eb-11f0-9d9c-a526edf9c303'\n",
            "    'Authorization': 'REDACTED'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 206\n",
            "Response headers:\n",
            "    'Server': 'Azurite-Blob/3.34.0'\n",
            "    'last-modified': 'Fri, 05 Sep 2025 00:03:34 GMT'\n",
            "    'x-ms-creation-time': 'REDACTED'\n",
            "    'content-length': '147568'\n",
            "    'content-type': 'application/octet-stream'\n",
            "    'content-range': 'REDACTED'\n",
            "    'etag': '\"0x23DB91A2D5C27A0\"'\n",
            "    'x-ms-blob-type': 'REDACTED'\n",
            "    'x-ms-lease-state': 'REDACTED'\n",
            "    'x-ms-lease-status': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'c39cad62-89eb-11f0-9d9c-a526edf9c303'\n",
            "    'x-ms-request-id': 'd3bf55e4-8458-4d21-8993-e8241a092257'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'accept-ranges': 'REDACTED'\n",
            "    'date': 'Fri, 05 Sep 2025 00:03:34 GMT'\n",
            "    'x-ms-server-encrypted': 'REDACTED'\n",
            "    'x-ms-blob-content-md5': 'REDACTED'\n",
            "    'Connection': 'keep-alive'\n",
            "    'Keep-Alive': 'REDACTED'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "INTEGRATED PIPELINE TEST\n",
            "==================================================\n",
            "Starting integrated pipeline for document: test-document-001\n",
            "  - Filename: loan_application.pdf\n",
            "  - Blob path: raw/test-document-001.pdf\n",
            "Step 1: Loading document from blob storage...\n",
            "Downloaded blob: raw/test-document-001.pdf\n",
            "  - Loaded loan_application.pdf from blob storage (147568 bytes)\n",
            "Step 2: OCR Processing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.ocr.easyocr_client:Processing PDF from bytes (size: 147568 bytes)\n",
            "INFO:src.ocr.easyocr_client:Successfully converted PDF to 1 images\n",
            "/Users/markuskuehnle/Documents/projects/credit-ocr-system/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - Extracted 62 text elements\n",
            "Step 3: Normalizing OCR results...\n",
            "  - Normalized to 26 structured items\n",
            "Step 4: Converting NumPy types...\n",
            "Step 5: LLM Field Extraction...\n"
          ]
        }
      ],
      "source": [
        "# Run the integrated pipeline with document parameters\n",
        "print(\"=\" * 50)\n",
        "print(\"INTEGRATED PIPELINE TEST\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Use the document that was uploaded to blob storage\n",
        "document_id = \"test-document-001\"\n",
        "filename = \"loan_application.pdf\"\n",
        "blob_path = f\"{Stage.RAW.value}/{document_id}.pdf\"\n",
        "\n",
        "results = await integrated_pipeline(document_id, filename, blob_path)\n",
        "print(\"=\" * 50)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
